{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.config import cfg\n",
    "\n",
    "from lib.dataset.dataset2D import Dataset2D\n",
    "from lib.dataset.dataset3D import Dataset3D\n",
    "from lib.hybridnet.efficienttrack.efficienttrack import EfficientTrack\n",
    "import lib.hybridnet.efficienttrack.darkpose as darkpose\n",
    "\n",
    "from lib.config.project_manager import ProjectManager\n",
    "\n",
    "project = ProjectManager()\n",
    "project.load('Test_Project')\n",
    "\n",
    "#project.create_new(\n",
    "#    name = 'CSV Creation',\n",
    "#    dataset2D_path = '/home/trackingsetup/Documents/CombinedDataset/DatasetColleen',\n",
    "#    dataset3D_path = '/home/trackingsetup/Documents/CombinedDataset/DatasetColleen')\n",
    "\n",
    "cfg = project.get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset3D(cfg, set='train')\n",
    "val_set = Dataset3D(cfg, set='val')\n",
    "calibPaths = [training_set.coco.dataset['calibration']['intrinsics'], \n",
    "              training_set.coco.dataset['calibration']['extrinsics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib.hybridnet.modules.efficienttrack.darkpose as darkpose\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights = \"/home/timo/Desktop/HybridNet/projects/Ralph_Center_Test/models/efficienttrack/EfficientTrack-d0_210.pth\"\n",
    "\n",
    "centerDetect = EfficientTrack('CenterDetectInference', cfg, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "    \n",
    "\n",
    "video_paths = [\n",
    "    '/media/timo/Elements/Example_Recording/Camera_B.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_LBB.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_LBT.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_LC.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_LFB.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_LFT.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_RBB.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_RBT.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_RC.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_RFB.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_RFT.mp4',\n",
    "    '/media/timo/Elements/Example_Recording/Camera_T.mp4', \n",
    "]\n",
    "\n",
    "caps = []\n",
    "outs = []\n",
    "for path in video_paths:\n",
    "    caps.append(cv2.VideoCapture(path))\n",
    "    outs.append(cv2.VideoWriter(os.path.join('/home/timo/Desktop/HybridNet/Videos_Ralph_Center', path.split('/')[-1].split(\".\")[0] + \".avi\"), cv2.VideoWriter_fourcc('M','J', 'P', 'G'), 100, (1280,1024)))\n",
    "\n",
    "for cap in caps:\n",
    "        cap.set(1,0) #99640\n",
    "        \n",
    "def process(cap):\n",
    "    ret, img = cap.read()\n",
    "    return img\n",
    "        \n",
    "counter = 0\n",
    "    \n",
    "ret = True\n",
    "while ret:\n",
    "    if counter % 20 == 0:\n",
    "        print (counter)\n",
    "    counter += 1\n",
    "    imgs_orig = []\n",
    "    centerHMs = []\n",
    "    camsToUse = []\n",
    "\n",
    "    imgs_orig = Parallel(n_jobs=12, require='sharedmem')(delayed(process)(cap) for cap in caps)\n",
    "    imgs = torch.zeros(12,3,256,320)\n",
    "    for i,img in enumerate(imgs_orig[:]):\n",
    "        img = ((cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)/255.0-cfg.DATASET.MEAN)/cfg.DATASET.STD)\n",
    "        img = cv2.resize(img, (320,256))\n",
    "        imgs[i] = torch.from_numpy(cv2.resize(img, (320,256)).transpose(2,0,1))\n",
    "    \n",
    "    imgs = imgs.cuda()\n",
    "    outputs = centerDetect.model(imgs)\n",
    "    preds, maxvals = darkpose.get_final_preds(outputs[1].clamp(0,255).detach().cpu().numpy(), None)\n",
    "    camsToUse = []\n",
    "    \n",
    "    for i,val in enumerate(maxvals[:]):\n",
    "        if val > 180:\n",
    "            camsToUse.append(i)\n",
    "    \n",
    "    if len(camsToUse) >= 2:\n",
    "        center3D = torch.from_numpy(val_set.reproTool.reconstructPoint((preds.reshape(12,2)*8).transpose(), camsToUse))\n",
    "        reproPoints = val_set.reproTool.reprojectPoint(center3D)\n",
    "        \n",
    "        errors = []\n",
    "        errors_valid = []\n",
    "        for i in range(12):\n",
    "            if maxvals[i] > 180:\n",
    "                errors.append(np.linalg.norm(preds.reshape(12,2)[i]*8-reproPoints[i]))\n",
    "                errors_valid.append(np.linalg.norm(preds.reshape(12,2)[i]*8-reproPoints[i]))\n",
    "            else:\n",
    "                errors.append(0)\n",
    "        medianError = np.median(np.array(errors_valid))\n",
    "        print (\"Error: \", medianError)\n",
    "        print (\"Var based: \", medianError+2*np.sqrt(np.var(errors_valid)),medianError*4)\n",
    "        camsToUse = []\n",
    "        for i,val in enumerate(maxvals[:]):\n",
    "            if val > 180 and errors[i] < 2*medianError:\n",
    "                camsToUse.append(i)\n",
    "        center3D = torch.from_numpy(val_set.reproTool.reconstructPoint((preds.reshape(12,2)*8).transpose(), camsToUse))\n",
    "        reproPoints = val_set.reproTool.reprojectPoint(center3D)\n",
    "\n",
    "        for i in range(12):\n",
    "            colors = [(255,0,0), (255,0,0),(255,0,0),(255,0,0),(0,255,0),(0,255,0),(0,255,0),(0,255,0),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(255,255,0),(255,255,0),(255,255,0), (255,255,0),\n",
    "                              (0,255,255),(0,255,255),(0,255,255),(0,255,255), (255,0,255),(100,0,100),(100,0,100)]\n",
    "\n",
    "            cv2.circle(imgs_orig[i], (int(reproPoints[i][0]), int(reproPoints[i][1])), 2, (255,100,100), thickness=5)\n",
    "            for j in range(12):\n",
    "                if j in camsToUse:\n",
    "                    cv2.circle(imgs_orig[i], (100+j*90,200), int(errors[j]), (255,0,0), thickness=5)\n",
    "                else:\n",
    "                    cv2.circle(imgs_orig[i], (100+j*90,200), int(5), (100,100,100), thickness=5)\n",
    "            #cv2.putText(imgs_orig[i],str(error/12),(10,500), font, 4, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            heatmap = outputs[1][i].clamp(0,255).detach().transpose(2,0).transpose(0,1).cpu().int().numpy().astype(np.uint8)\n",
    "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "            added_image = cv2.addWeighted(imgs_orig[i],1.0, cv2.resize(heatmap, (1280,1024)),0.25,0)\n",
    "            outs[i].write(added_image)\n",
    "    \n",
    "\n",
    "    #hetamap = cv2.resize(outputs[1].clamp(0,255).detach().cpu().numpy()[11][0]/255., (320,256), interpolation=cv2.cv2.INTER_NEAREST)\n",
    "    #plt.imshow(hetamap, alpha=0.6)\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a20e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "    \n",
    "\n",
    "video_paths = [\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_B.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_LBB.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_LBT.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_LC.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_LFB.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_LFT.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_RBB.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_RBT.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_RC.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_RFB.avi',\n",
    "    '/media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_RFT.avi',\n",
    "    '//media/timo/Elements/Recordings/Ralph/Ralph_Test_15072021/Camera_T.avi', \n",
    "]\n",
    "\n",
    "caps = []\n",
    "outs = []\n",
    "for path in video_paths:\n",
    "    caps.append(cv2.VideoCapture(path))\n",
    "    outs.append(cv2.VideoWriter(os.path.join('/home/timo/Desktop/HybridNet/Videos_Ralph_Center', path.split('/')[-1]), cv2.VideoWriter_fourcc('M','J', 'P', 'G'), 100, (1280,1024)))\n",
    "\n",
    "for cap in caps:\n",
    "        cap.set(1,0) #99640\n",
    "        \n",
    "def process(cap):\n",
    "    ret, img = cap.read()\n",
    "    return img\n",
    "        \n",
    "counter = 0\n",
    "    \n",
    "ret = True\n",
    "while ret:\n",
    "    if counter % 20 == 0:\n",
    "        print (counter)\n",
    "    counter += 1\n",
    "    imgs_orig = []\n",
    "    centerHMs = []\n",
    "    camsToUse = []\n",
    "\n",
    "    imgs_orig = Parallel(n_jobs=12, require='sharedmem')(delayed(process)(cap) for cap in caps)\n",
    "    imgs = torch.zeros(12,3,256,320)\n",
    "    for i,img in enumerate(imgs_orig[:]):\n",
    "        img = ((cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)/255.0-cfg.DATASET.MEAN)/cfg.DATASET.STD)\n",
    "        img = cv2.resize(img, (320,256))\n",
    "        imgs[i] = torch.from_numpy(cv2.resize(img, (320,256)).transpose(2,0,1))\n",
    "    \n",
    "    imgs = imgs.cuda()\n",
    "    outputs = centerDetect.model(imgs)\n",
    "    preds, maxvals = darkpose.get_final_preds(outputs[1].clamp(0,255).detach().cpu().numpy(), None)\n",
    "    camsToUse = []\n",
    "    print (maxvals[0])\n",
    "    for i,val in enumerate(maxvals):\n",
    "        if val > 200:\n",
    "            camsToUse.append(i)\n",
    "    \n",
    "    print (preds.shape)\n",
    "        \n",
    "    if len(camsToUse) >= 2:\n",
    "        center3D = torch.from_numpy(val_set.reproTool.reconstructPoint((preds.reshape(12,2)*8).transpose(), camsToUse))\n",
    "        center3D = center3D.int()\n",
    "        reproPoints = val_set.reproTool.reprojectPoint(center3D)\n",
    "        error = 0\n",
    "        for i in range(12):\n",
    "            if maxvals[i] > 200:\n",
    "                error += np.linalg.norm(preds.reshape(12,2)[i]*8-reproPoints[i])\n",
    "        print (reproPoints[0])\n",
    "        for i in range(12):\n",
    "            colors = [(255,0,0), (255,0,0),(255,0,0),(255,0,0),(0,255,0),(0,255,0),(0,255,0),(0,255,0),(0,0,255),(0,0,255),(0,0,255),(0,0,255),(255,255,0),(255,255,0),(255,255,0), (255,255,0),\n",
    "                              (0,255,255),(0,255,255),(0,255,255),(0,255,255), (255,0,255),(100,0,100),(100,0,100)]\n",
    "\n",
    "            #cv2.circle(imgs_orig[i], (int(reproPoints[i][0]), int(reproPoints[i][1])), 2, (255,100,100), thickness=5)\n",
    "            #cv2.circle(imgs_orig[i], (200,200), int(error/12), (255,0,0), thickness=5)#\n",
    "            heatmap = outputs[1][i].clamp(0,255).detach().transpose(2,0).transpose(0,1).cpu().int().numpy().astype(np.uint8)\n",
    "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "            added_image = cv2.addWeighted(imgs_orig[i],1.0, cv2.resize(heatmap, (1280,1024)),0.3,0)\n",
    "            #cv2.putText(imgs_orig[i],str(error/12),(10,500), font, 4, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            outs[i].write(added_image)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "\n",
    "    #hetamap = cv2.resize(outputs[1].clamp(0,255).detach().cpu().numpy()[11][0]/255., (320,256), interpolation=cv2.cv2.INTER_NEAREST)\n",
    "    #plt.imshow(hetamap, alpha=0.6)\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import cm\n",
    "\n",
    "figure = plt.figure()\n",
    "axes = figure.gca(projection='3d')\n",
    "\n",
    "c = ['r', 'r','r','r','b','b','b','b','g','g','g','g', 'orange', 'orange','orange','orange', 'y','y','y','y','purple', 'purple','purple']\n",
    "line_idxs = [[0,1], [1,2], [2,3], [4,5], [5,6], [6,7], [8,9], [9,10], [10,11], [12,13], [13,14], [14,15], [16,17], [17,18], [18,19], [3,7], [7,11], [11,15], [3,21], [7,21],[11,22], [15,22],[21,22], [18,15], [19,22]]\n",
    "points3D = points3D_net[0].cpu().numpy()\n",
    "center3D = center3D.cpu()\n",
    "for i, point in enumerate(points3D):\n",
    "    #print (\"Classic:\", i, point)\n",
    "    if i != 20:\n",
    "        axes.scatter(point[0], point[1], point[2], color = c[i])\n",
    "for line in line_idxs:\n",
    "    axes.plot([points3D[line[0]][0], points3D[line[1]][0]], [points3D[line[0]][1], points3D[line[1]][1]], [points3D[line[0]][2], points3D[line[1]][2]], c = 'gray')\n",
    "\n",
    "axes.set_xlim3d(center3D[0]-100, center3D[0]+100)\n",
    "axes.set_ylim3d(center3D[1]-100, center3D[1]+100)\n",
    "axes.set_zlim3d(center3D[2]-100, center3D[2]+100)\n",
    "plt.subplots_adjust(left=0., right=1., top=1., bottom=0.)\n",
    "#plt.gca().invert_zaxis()\n",
    "plt.savefig('test.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
